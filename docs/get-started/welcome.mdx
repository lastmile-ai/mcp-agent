---
title: "Welcome to mcp-agent"
sidebarTitle: "Welcome"
description: Build effective agents with Model Context Protocol using simple, composable patterns.
icon: hand-wave
---

<img
  src="/logo/mcp-agent-logo.png"
  alt="mcp-agent logo"
  noZoom
  className="rounded-2xl block"
/>

[`mcp-agent`](https://github.com/lastmile-ai/mcp-agent) is a simple, composable framework to build effective agents using [Model Context Protocol](https://modelcontextprotocol.io/introduction).

**mcp-agent**'s vision is that MCP is all you need to build agents, and that simple patterns are more robust than complex architectures for shipping high-quality agents.
When you're ready to deploy, [`mcp-c`](https://docs.mcp-agent.com/get-started/cloud) let's you deploy any kind of MCP server to a managed Cloud. You can even deploy agents as MCP servers!

## Why teams pick mcp-agent

<CardGroup cols={2}>
  <Card title="MCP-native" icon="plug">
    Fully implements the MCP spec, including auth, elicitation, sampling, and notifications.
  </Card>
  <Card title="Composable patterns" icon="puzzle-piece">
    Map-reduce, router, deep research, evaluator — every pattern from Anthropic's [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) guide ships as a first-class workflow.
  </Card>
  <Card title="Built for Production" icon="shield">
    Durable execution with Temporal, OpenTelemetry observability, and cloud deployment via the CLI.
  </Card>
  <Card title="Lightweight & Pythonic" icon="feather">
    Define an agent with a few lines of Python—mcp-agent handles the lifecycle, connections, and MCP server wiring for you.
  </Card>
</CardGroup>

```python {1}
import asyncio
from mcp_agent.app import MCPApp
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM

app = MCPApp(name="researcher")

async def main():
    async with app.run() as session:
        agent = Agent(
            name="researcher",
            instruction="Use available tools to gather concise answers.",
            server_names=["fetch", "filesystem"],
        )

        async with agent:
            llm = await agent.attach_llm(OpenAIAugmentedLLM)
            report = await llm.generate_str("Summarize the latest MCP news")
            print(report)

if __name__ == "__main__":
    asyncio.run(main())
```

## Next steps

<CardGroup cols={2}>
  <Card
    title="Quickstart"
    icon="rocket-launch"
    href="/get-started/quickstart"
  >
    Scaffold an agent with `uvx mcp-agent init` and run it locally in under 5 minutes.
  </Card>
  <Card
    title="Deploy to Cloud"
    icon="cloud"
    href="/get-started/cloud"
  >
    Deploy any kind of MCP server using `mcp-c`. Use `uvx mcp-agent deploy` to host your agent as a managed MCP server.
  </Card>
  <Card
    title="Explore the patterns"
    icon="diagram-project"
    href="/mcp-agent-sdk/effective-patterns/overview"
  >
    Learn how to combine planner, router, evaluator, and more.
  </Card>
</CardGroup>

### Build with LLMs

The docs are also available in [llms.txt format](https://llmstxt.org/):
- [llms.txt](https://docs.mcp-agent.com/llms.txt) - A sitemap listing all documentation pages
- [llms-full.txt](https://docs.mcp-agent.com/llms-full.txt) - The entire documentation in one file (may exceed context windows)
- [docs MCP server](https://docs.mcp-agent.com/mcp) - Directly connect the docs to an MCP-compatible AI coding assistant.
